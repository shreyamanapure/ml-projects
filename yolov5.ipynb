{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmc3UBBZSSu9y7aDBYzU9E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyamanapure/ml-projects/blob/main/yolov5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd_nHZmzJduZ",
        "outputId": "06fe85f3-24e8-4fc9-c3c8-454558a316a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ğŸš€ v7.0-178-ga199480 Python-3.10.12 torch-2.0.1+cu118 CPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 23.3/107.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source data/images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpxLE7TGJnNQ",
        "outputId": "3a29a0bf-39a9-4d11-8474-838792a31c55"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5s.pt'], source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ğŸš€ v7.0-178-ga199480 Python-3.10.12 torch-2.0.1+cu118 CPU\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 225MB/s]\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
            "image 1/2 /content/yolov5/data/images/bus.jpg: 640x480 4 persons, 1 bus, 348.2ms\n",
            "image 2/2 /content/yolov5/data/images/zidane.jpg: 384x640 2 persons, 2 ties, 260.4ms\n",
            "Speed: 2.0ms pre-process, 304.3ms inference, 13.4ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.hub.download_url_to_file('https://ultralytics.com/assets/coco2017val.zip', 'tmp.zip')  # download (780M - 5000 images)\n",
        "!unzip -q tmp.zip -d ../datasets && rm tmp.zip  # unzip\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTlmCchdJuyd",
        "outputId": "c46efb64-e210-443a-f818-eedbd941a6f6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 780M/780M [00:12<00:00, 66.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python val.py --weights yolov5s.pt --data coco.yaml --img 640 --half"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1o9X3t4jJ66_",
        "outputId": "2e83a09c-ec7d-4137-a86c-c61aa10b440d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/yolov5/data/coco.yaml, weights=['yolov5s.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False\n",
            "YOLOv5 ğŸš€ v7.0-178-ga199480 Python-3.10.12 torch-2.0.1+cu118 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco/val2017... 4952 images, 48 backgrounds, 0 corrupt: 100% 5000/5000 [00:03<00:00, 1398.86it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/coco/val2017.cache\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/157 [00:01<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/val.py\", line 409, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/val.py\", line 380, in main\n",
            "    run(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/yolov5/val.py\", line 210, in run\n",
            "    preds, train_out = model(im) if compute_loss else (model(im, augment=augment), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/yolov5/models/common.py\", line 515, in forward\n",
            "    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/yolov5/models/yolo.py\", line 209, in forward\n",
            "    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n",
            "  File \"/content/yolov5/models/yolo.py\", line 121, in _forward_once\n",
            "    x = m(x)  # run\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/yolov5/models/common.py\", line 59, in forward_fuse\n",
            "    return self.act(self.conv(x))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
            "    return F.conv2d(input, weight, bias, self.stride,\n",
            "RuntimeError: \"slow_conv2d_cpu\" not implemented for 'Half'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logger = 'Comet' #@param ['Comet', 'ClearML', 'TensorBoard']\n",
        "\n",
        "if logger == 'Comet':\n",
        "  %pip install -q comet_ml\n",
        "  import comet_ml; comet_ml.init()\n",
        "elif logger == 'ClearML':\n",
        "  %pip install -q clearml\n",
        "  import clearml; clearml.browser_login()\n",
        "elif logger == 'TensorBoard':\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir runs/train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3DxkfXpKC4S",
        "outputId": "379b8740-0a9c-41f0-d562-1b32e8c8f907"
      },
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m534.7/534.7 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m206.7/206.7 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m510.1/510.1 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m123.6/123.6 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mPlease paste your Comet API key from https://www.comet.com/api/my/settings/\n",
            "(api key may not show as you type)\n",
            "Comet API key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Valid Comet API Key saved in /root/.comet.config (set COMET_CONFIG to change where it is saved).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov5s.pt --cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iS4_93fZKa1D",
        "outputId": "87b7baac-4bc3-4ce7-a7ce-b91fb3cb6e57"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=coco128.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=3, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ğŸš€ v7.0-178-ga199480 Python-3.10.12 torch-2.0.1+cu118 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 ğŸš€ in ClearML\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: tensorboard, keras, tensorflow, torch.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com \u001b[38;5;39mhttps://www.comet.com/shreyamanapure/yolov5/5cd2b7a593f2419a9955d52ebe677b6b\u001b[0m\n",
            "\n",
            "\n",
            "Dataset not found âš ï¸, missing paths ['/content/datasets/coco128/images/train2017']\n",
            "Downloading https://ultralytics.com/assets/coco128.zip to coco128.zip...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.66M/6.66M [00:00<00:00, 104MB/s]\n",
            "Dataset download success âœ… (0.7s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7235389 parameters, 7235389 gradients, 16.6 GFLOPs\n",
            "\n",
            "Transferred 349/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco128/labels/train2017... 126 images, 2 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<00:00, 862.30it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/coco128/labels/train2017.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<00:00, 190.49it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:01<00:00, 70.66it/s] \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.27 anchors/target, 0.994 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/2         0G    0.04618    0.07207    0.01702        232        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [03:35<00:00, 26.91s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [01:08<00:00, 17.11s/it]\n",
            "                   all        128        929      0.673      0.598       0.68       0.45\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/2         0G    0.04622     0.0689    0.01817        201        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [03:16<00:00, 24.55s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:58<00:00, 14.68s/it]\n",
            "                   all        128        929       0.71      0.645      0.722      0.478\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/2         0G     0.0436     0.0647    0.01698        227        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [03:16<00:00, 24.56s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:58<00:00, 14.63s/it]\n",
            "                   all        128        929      0.761      0.647      0.733      0.491\n",
            "\n",
            "3 epochs completed in 0.221 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 14.8MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 14.8MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [01:01<00:00, 15.35s/it]\n",
            "                   all        128        929      0.761      0.645      0.733      0.491\n",
            "                person        128        254      0.859      0.705      0.804      0.529\n",
            "               bicycle        128          6      0.772      0.575      0.627      0.408\n",
            "                   car        128         46      0.667      0.435      0.549      0.246\n",
            "            motorcycle        128          5      0.588        0.8      0.837      0.635\n",
            "              airplane        128          6          1      0.987      0.995      0.698\n",
            "                   bus        128          7      0.636      0.714      0.753      0.647\n",
            "                 train        128          3      0.687      0.333       0.72      0.504\n",
            "                 truck        128         12      0.605      0.333      0.472       0.26\n",
            "                  boat        128          6      0.944      0.333      0.456       0.18\n",
            "         traffic light        128         14      0.778      0.254        0.4      0.217\n",
            "             stop sign        128          2      0.825          1      0.995      0.895\n",
            "                 bench        128          9      0.692      0.503      0.668      0.315\n",
            "                  bird        128         16      0.962          1      0.995      0.655\n",
            "                   cat        128          4       0.87          1      0.995      0.754\n",
            "                   dog        128          9          1      0.652      0.899      0.651\n",
            "                 horse        128          2      0.853          1      0.995      0.622\n",
            "              elephant        128         17      0.908      0.882      0.934      0.695\n",
            "                  bear        128          1      0.697          1      0.995      0.995\n",
            "                 zebra        128          4      0.856          1      0.995      0.905\n",
            "               giraffe        128          9      0.787      0.825      0.912      0.701\n",
            "              backpack        128          6      0.837        0.5      0.715      0.302\n",
            "              umbrella        128         18      0.785      0.814      0.859      0.486\n",
            "               handbag        128         19      0.767      0.263      0.347      0.203\n",
            "                   tie        128          7      0.989      0.714       0.77       0.49\n",
            "              suitcase        128          4      0.656          1      0.945      0.606\n",
            "               frisbee        128          5      0.721        0.8      0.759      0.708\n",
            "                  skis        128          1      0.737          1      0.995        0.3\n",
            "             snowboard        128          7      0.831      0.704       0.83      0.569\n",
            "           sports ball        128          6      0.637      0.667      0.602      0.309\n",
            "                  kite        128         10      0.638        0.6      0.599      0.226\n",
            "          baseball bat        128          4      0.503       0.25      0.467      0.205\n",
            "        baseball glove        128          7      0.577      0.429      0.465      0.314\n",
            "            skateboard        128          5      0.929        0.6      0.687      0.493\n",
            "         tennis racket        128          7       0.77      0.429      0.547      0.332\n",
            "                bottle        128         18      0.576      0.379      0.553      0.275\n",
            "            wine glass        128         16      0.741      0.875      0.902      0.493\n",
            "                   cup        128         36      0.842      0.667      0.835      0.533\n",
            "                  fork        128          6      0.996      0.333      0.457      0.316\n",
            "                 knife        128         16      0.769      0.688      0.696        0.4\n",
            "                 spoon        128         22      0.837      0.469      0.636      0.383\n",
            "                  bowl        128         28      0.753      0.571      0.716      0.513\n",
            "                banana        128          1      0.905          1      0.995      0.301\n",
            "              sandwich        128          2          1          0      0.359      0.326\n",
            "                orange        128          4      0.737       0.75      0.912      0.581\n",
            "              broccoli        128         11       0.55      0.364      0.429      0.313\n",
            "                carrot        128         24      0.621      0.625      0.725      0.489\n",
            "               hot dog        128          2      0.408          1      0.828      0.828\n",
            "                 pizza        128          5      0.833      0.998      0.962      0.727\n",
            "                 donut        128         14      0.631          1       0.96      0.839\n",
            "                  cake        128          4      0.871          1      0.995       0.83\n",
            "                 chair        128         35      0.583      0.599      0.608      0.316\n",
            "                 couch        128          6      0.909      0.667      0.813      0.543\n",
            "          potted plant        128         14      0.739      0.786      0.824      0.474\n",
            "                   bed        128          3       0.99      0.333       0.83      0.441\n",
            "          dining table        128         13      0.822      0.358      0.578      0.342\n",
            "                toilet        128          2          1       0.98      0.995      0.846\n",
            "                    tv        128          2      0.571          1      0.995      0.796\n",
            "                laptop        128          3          1          0      0.593      0.312\n",
            "                 mouse        128          2          1          0     0.0892     0.0446\n",
            "                remote        128          8          1      0.623      0.633      0.538\n",
            "            cell phone        128          8       0.62      0.413      0.421      0.188\n",
            "             microwave        128          3      0.711          1      0.995      0.736\n",
            "                  oven        128          5      0.328        0.4       0.43      0.282\n",
            "                  sink        128          6       0.44      0.333      0.343      0.269\n",
            "          refrigerator        128          5      0.569        0.8      0.799      0.536\n",
            "                  book        128         29      0.595      0.254      0.357      0.167\n",
            "                 clock        128          9      0.766      0.889      0.932      0.736\n",
            "                  vase        128          2      0.332          1      0.995      0.895\n",
            "              scissors        128          1          1          0      0.497     0.0547\n",
            "            teddy bear        128         21      0.856      0.568      0.836      0.544\n",
            "            toothbrush        128          5        0.8          1      0.928      0.574\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : \u001b[38;5;39mhttps://www.comet.com/shreyamanapure/yolov5/5cd2b7a593f2419a9955d52ebe677b6b\u001b[0m\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP_0.5 [3]      : (0.6802414486796934, 0.7332563177228386)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP_0.5:0.95 [3] : (0.44985371008923614, 0.49127684331269467)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision [3]    : (0.6727220972127114, 0.7609709724254711)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall [3]       : (0.5979460825508643, 0.6466476164688112)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [3]       : (0.04360061138868332, 0.04622416943311691)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [3]       : (0.01698106713593006, 0.018166562542319298)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/obj_loss [3]       : (0.06470181792974472, 0.07207418978214264)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [3]         : (0.04030284285545349, 0.041302718222141266)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [3]         : (0.008896910585463047, 0.0108173917979002)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/obj_loss [3]         : (0.03684026747941971, 0.03821956366300583)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     x/lr0 [3]                : (0.077782, 0.0937)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     x/lr1 [3]                : (0.0007, 0.001005)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     x/lr2 [3]                : (0.0007, 0.001005)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Created from                : YOLOv5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Run Path                    : shreyamanapure/yolov5/5cd2b7a593f2419a9955d52ebe677b6b\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_log_batch_metrics     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_log_confusion_matrix  : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_log_per_class_metrics : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_max_image_uploads     : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_mode                  : online\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_model_name            : yolov5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     anchor_t           : 4.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     artifact_alias     : latest\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_size         : 16\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bbox_interval      : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box                : 0.05\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bucket             : \n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg                : \n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls                : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls_pw             : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees            : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device             : \n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     entity             : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     evolve             : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fl_gamma           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr             : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud             : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze             : [0]\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h              : 0.015\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s              : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v              : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp                : {\"anchor_t\": 4.0, \"box\": 0.05, \"cls\": 0.5, \"cls_pw\": 1.0, \"copy_paste\": 0.0, \"degrees\": 0.0, \"fl_gamma\": 0.0, \"fliplr\": 0.5, \"flipud\": 0.0, \"hsv_h\": 0.015, \"hsv_s\": 0.7, \"hsv_v\": 0.4, \"iou_t\": 0.2, \"lr0\": 0.01, \"lrf\": 0.01, \"mixup\": 0.0, \"momentum\": 0.937, \"mosaic\": 1.0, \"obj\": 1.0, \"obj_pw\": 1.0, \"perspective\": 0.0, \"scale\": 0.5, \"shear\": 0.0, \"translate\": 0.1, \"warmup_bias_lr\": 0.1, \"warmup_epochs\": 3.0, \"warmup_momentum\": 0.8, \"weight_decay\": 0.0005}\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     image_weights      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz              : 640\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou_t              : 0.2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     label_smoothing    : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     local_rank         : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0                : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf                : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup              : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum           : 0.937\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic             : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name               : exp\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     noautoanchor       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     noplots            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nosave             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     noval              : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     obj                : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     obj_pw             : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer          : SGD\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience           : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective        : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project            : runs/train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     quad               : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect               : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir           : runs/train/exp\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period        : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale              : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed               : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear              : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     sync_bn            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate          : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     upload_dataset     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_conf_threshold : 0.001\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_iou_threshold  : 0.6\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr     : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs      : 3.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum    : 0.8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay       : 0.0005\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers            : 8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     asset               : 13 (3.87 MB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata        : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: tensorboard, keras, tensorflow, torch.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 1 metrics, params and output messages\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', force_reload=True)  # yolov5n - yolov5x6 or custom\n",
        "im = 'https://ultralytics.com/images/zidane.jpg'  # file, Path, PIL.Image, OpenCV, nparray, list\n",
        "results = model(im)  # inference\n",
        "results.print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_4G2qO1LG1_",
        "outputId": "ef755caa-08d8-44a4-ab01-c17c277da8e7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "YOLOv5 ğŸš€ v7.0-178-ga199480 Python-3.10.12 torch-2.0.1+cu118 CPU\n",
            "\n",
            "Fusing layers... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/usr/local/lib/python3.10/dist-packages/requests-2.27.1.dist-info/METADATA'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
            "Adding AutoShape... \n",
            "image 1/1: 720x1280 2 persons, 2 ties\n",
            "Speed: 265.4ms pre-process, 283.0ms inference, 4.5ms NMS per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4y3llXpjO0YD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}